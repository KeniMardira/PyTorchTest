{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # standard basic library for pytorch\n",
    "import torch.autograd # need Variable class\n",
    "import torch.nn as nn # need the basic neural net module\n",
    "import torch.nn.functional as F # imported for the conv1d function\n",
    "\n",
    "import torch.nn.parameter as Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convFilter = torch.FloatTensor([8,2]) # use [8,2] for test kernel\n",
    "convFilter = torch.unsqueeze(convFilter,0) # unsqueeze twice to make filter a 3 dimensional 1x1x2 filter\n",
    "convFilter = torch.unsqueeze(convFilter,0)\n",
    "convInput = torch.unsqueeze(torch.autograd.Variable(torch.FloatTensor([3,7,6,4])),0) # use [3,7,6,4] as test input\n",
    "convInput = torch.unsqueeze(convInput,0) #unsqueeze twice to make input 3D 1x1x4 for the Conv1D class\n",
    "print(convInput)\n",
    "\n",
    "\n",
    "conv = torch.nn.Conv1d(1,1,2,padding = 0, bias = False) # set bias to false for now since no learning is required yet\n",
    "conv.weight = torch.nn.Parameter(convFilter) # set weight of conv filter to be what was specified\n",
    "print(conv.weight)\n",
    "\n",
    "convOutput = conv(convInput) # convolve input with filter --> this should give non-causal convolution\n",
    "print(convOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv(torch.nn.Conv1d): # a class for causal convolution exclusively\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(CausalConv,self).__init__(in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation = 1, groups = 1, bias = False) # initialise with Conv1d init variables\n",
    "        self.causality_padding = kernel_size - 1 # padding size depends on kernel size; output at t depend on input t-n...input t\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        inputs = F.pad(inputs, (self.causality_padding,0,0,0))\n",
    "        return F.conv1d(inputs, self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_conv = CausalConv(1,1,2)\n",
    "causal_conv.weight = torch.nn.Parameter(convFilter)\n",
    "causal_conv_output = causal_conv(convInput)\n",
    "\n",
    "print(causal_conv_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
